{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food-101 Image Classifier — MobileNetV2 Transfer Learning\n",
    "\n",
    "Train a food image classifier for the **Smart Nutrition Tracker** project.\n",
    "\n",
    "- **Dataset**: Food-101 (101 categories, 101K images)\n",
    "- **Model**: MobileNetV2 (pretrained on ImageNet)\n",
    "- **Strategy**: 2-phase transfer learning\n",
    "- **Output**: `food_classifier.pth` + `food_classes.json`\n",
    "\n",
    "**Runtime**: Go to `Runtime > Change runtime type > T4 GPU`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import transforms, models\nfrom torchvision.datasets import Food101\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport json\nimport time\nimport os\nfrom collections import defaultdict\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Device: {device}\")\nif device.type == 'cuda':\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Food-101 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Data transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Downloading Food-101 dataset (~5GB, takes a few minutes)...\")\n",
    "train_dataset = Food101(root='./data', split='train', download=True, transform=train_transform)\n",
    "test_dataset = Food101(root='./data', split='test', download=True, transform=test_transform)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset):,}\")\n",
    "print(f\"Test samples:     {len(test_dataset):,}\")\n",
    "print(f\"Classes:          {len(train_dataset.classes)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save class names for later use in the project\n",
    "class_names = train_dataset.classes\n",
    "class_to_idx = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "print(\"Food categories:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"  {i:3d}. {name.replace('_', ' ').title()}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                         num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Test batches:  {len(test_loader)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def show_samples(dataset, n=12):\n",
    "    \"\"\"Show sample images from the dataset.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 6, figsize=(18, 6))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "    indices = np.random.choice(len(dataset), n, replace=False)\n",
    "    for i, idx in enumerate(indices):\n",
    "        img, label = dataset[idx]\n",
    "        img = img.numpy().transpose(1, 2, 0)\n",
    "        img = std * img + mean  # denormalize\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        ax = axes[i // 6][i % 6]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(class_names[label].replace('_', ' ').title(), fontsize=10)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples(train_dataset)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Model — MobileNetV2 + Custom Head"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def build_model(num_classes=101, freeze_backbone=True):\n",
    "    \"\"\"MobileNetV2 with custom classifier head.\"\"\"\n",
    "    model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    # Freeze backbone\n",
    "    if freeze_backbone:\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Replace classifier (original: 1280 -> 1000 for ImageNet)\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(1280, num_classes)\n",
    "    )\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "model = build_model(num_classes=101, freeze_backbone=True)\n",
    "\n",
    "# Count parameters\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters:     {total:,}\")\n",
    "print(f\"Trainable parameters: {trainable:,}\")\n",
    "print(f\"Frozen parameters:    {total - trainable:,}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        if (batch_idx + 1) % 200 == 0:\n",
    "            print(f\"    batch {batch_idx+1}/{len(loader)} — \"\n",
    "                  f\"loss: {total_loss/total:.4f}, acc: {100.*correct/total:.1f}%\")\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Phase 1 — Train Classifier Head Only (backbone frozen)\n",
    "\n",
    "Fast convergence: only the final layer learns to map ImageNet features to food categories."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "\n",
    "PHASE1_EPOCHS = 5\n",
    "history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PHASE 1: Training classifier head (backbone frozen)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(PHASE1_EPOCHS):\n",
    "    start = time.time()\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
    "    scheduler.step()\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(test_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{PHASE1_EPOCHS} ({elapsed:.0f}s) — \"\n",
    "          f\"Train: {100*train_acc:.1f}% | Test: {100*test_acc:.1f}% | \"\n",
    "          f\"LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "print(f\"\\nPhase 1 complete — Test accuracy: {100*history['test_acc'][-1]:.1f}%\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Phase 2 — Fine-tune Entire Model (backbone unfrozen)\n",
    "\n",
    "Unfreeze all layers and train with a lower learning rate for higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Unfreeze backbone\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters after unfreeze: {trainable:,}\")\n",
    "\n",
    "# Lower LR to avoid destroying pretrained weights\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
    "\n",
    "PHASE2_EPOCHS = 10\n",
    "best_acc = max(history['test_acc'])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PHASE 2: Fine-tuning entire model\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(PHASE2_EPOCHS):\n",
    "    start = time.time()\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
    "    scheduler.step()\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(test_acc)\n",
    "\n",
    "    # Save best model\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'food_classifier_best.pth')\n",
    "        marker = ' << BEST'\n",
    "    else:\n",
    "        marker = ''\n",
    "\n",
    "    total_epoch = PHASE1_EPOCHS + epoch + 1\n",
    "    print(f\"Epoch {total_epoch}/{PHASE1_EPOCHS+PHASE2_EPOCHS} ({elapsed:.0f}s) — \"\n",
    "          f\"Train: {100*train_acc:.1f}% | Test: {100*test_acc:.1f}%{marker}\")\n",
    "\n",
    "print(f\"\\nPhase 2 complete — Best test accuracy: {100*best_acc:.1f}%\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "phase1_end = PHASE1_EPOCHS\n",
    "\n",
    "# Loss\n",
    "ax1.plot(epochs, history['train_loss'], 'b-', label='Train Loss')\n",
    "ax1.plot(epochs, history['test_loss'], 'r-', label='Test Loss')\n",
    "ax1.axvline(x=phase1_end, color='gray', linestyle='--', alpha=0.5, label='Unfreeze backbone')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "ax2.plot(epochs, [a*100 for a in history['train_acc']], 'b-', label='Train Acc')\n",
    "ax2.plot(epochs, [a*100 for a in history['test_acc']], 'r-', label='Test Acc')\n",
    "ax2.axvline(x=phase1_end, color='gray', linestyle='--', alpha=0.5, label='Unfreeze backbone')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Food-101 — MobileNetV2 Transfer Learning', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('food_classifier_best.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Collect all predictions\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Overall accuracy\n",
    "top1_acc = (all_preds == all_labels).mean()\n",
    "print(f\"Top-1 Accuracy: {100*top1_acc:.2f}%\")\n",
    "\n",
    "# Per-class accuracy (top 10 and bottom 10)\n",
    "class_correct = defaultdict(int)\n",
    "class_total = defaultdict(int)\n",
    "for pred, label in zip(all_preds, all_labels):\n",
    "    class_total[label] += 1\n",
    "    if pred == label:\n",
    "        class_correct[label] += 1\n",
    "\n",
    "class_acc = {cls: class_correct[cls] / class_total[cls] for cls in class_total}\n",
    "sorted_classes = sorted(class_acc.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\nTop 10 easiest classes:\")\n",
    "for cls_idx, acc in sorted_classes[:10]:\n",
    "    print(f\"  {class_names[cls_idx]:25s} {100*acc:.1f}%\")\n",
    "\n",
    "print(f\"\\nTop 10 hardest classes:\")\n",
    "for cls_idx, acc in sorted_classes[-10:]:\n",
    "    print(f\"  {class_names[cls_idx]:25s} {100*acc:.1f}%\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def show_predictions(model, dataset, n=12):\n",
    "    \"\"\"Show predictions on random test images.\"\"\"\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(2, 6, figsize=(18, 7))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "    indices = np.random.choice(len(dataset), n, replace=False)\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        img, label = dataset[idx]\n",
    "\n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            output = model(img.unsqueeze(0).to(device))\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            confidence, predicted = probs.max(1)\n",
    "\n",
    "        # Denormalize for display\n",
    "        img_np = img.numpy().transpose(1, 2, 0)\n",
    "        img_np = std * img_np + mean\n",
    "        img_np = np.clip(img_np, 0, 1)\n",
    "\n",
    "        ax = axes[i // 6][i % 6]\n",
    "        ax.imshow(img_np)\n",
    "\n",
    "        pred_name = class_names[predicted.item()].replace('_', ' ').title()\n",
    "        true_name = class_names[label].replace('_', ' ').title()\n",
    "        conf = confidence.item() * 100\n",
    "\n",
    "        correct = predicted.item() == label\n",
    "        color = 'green' if correct else 'red'\n",
    "        ax.set_title(f\"Pred: {pred_name}\\n({conf:.0f}%)\\nTrue: {true_name}\",\n",
    "                     fontsize=8, color=color)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle('Test Predictions (green=correct, red=wrong)', fontsize=13)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_predictions.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "show_predictions(model, test_dataset)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Measure Inference Speed\n",
    "\n",
    "This is important for protocol benchmarking — we need to know the model's inference time\n",
    "so we can separate it from protocol overhead."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Benchmark inference speed\n",
    "model.eval()\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "# Warmup\n",
    "for _ in range(20):\n",
    "    with torch.no_grad():\n",
    "        _ = model(dummy_input)\n",
    "\n",
    "# Measure\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "times = []\n",
    "for _ in range(100):\n",
    "    start = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        _ = model(dummy_input)\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    times.append((time.perf_counter() - start) * 1000)\n",
    "\n",
    "times = np.array(times)\n",
    "print(f\"Inference speed (single image):\")\n",
    "print(f\"  Mean:  {times.mean():.2f} ms\")\n",
    "print(f\"  P50:   {np.percentile(times, 50):.2f} ms\")\n",
    "print(f\"  P95:   {np.percentile(times, 95):.2f} ms\")\n",
    "print(f\"  P99:   {np.percentile(times, 99):.2f} ms\")\n",
    "print(f\"\\nThis is the baseline inference time.\")\n",
    "print(f\"Protocol overhead = total_time - inference_time\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Export Model for Deployment\n",
    "\n",
    "Save everything needed to run inference in the Smart Nutrition Tracker project."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1. Save model weights\n",
    "torch.save(model.state_dict(), 'food_classifier.pth')\n",
    "\n",
    "# 2. Save class mapping\n",
    "class_info = {\n",
    "    'classes': class_names,\n",
    "    'class_to_idx': class_to_idx,\n",
    "    'num_classes': len(class_names),\n",
    "    'model_arch': 'mobilenet_v2',\n",
    "    'input_size': 224,\n",
    "    'normalize_mean': [0.485, 0.456, 0.406],\n",
    "    'normalize_std': [0.229, 0.224, 0.225],\n",
    "    'accuracy': float(f'{100*best_acc:.2f}'),\n",
    "    'inference_time_ms': float(f'{times.mean():.2f}')\n",
    "}\n",
    "\n",
    "with open('food_classes.json', 'w') as f:\n",
    "    json.dump(class_info, f, indent=2)\n",
    "\n",
    "# 3. Save training history\n",
    "with open('training_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "# Check file sizes\n",
    "for fname in ['food_classifier.pth', 'food_classifier_best.pth', 'food_classes.json']:\n",
    "    size = os.path.getsize(fname)\n",
    "    print(f\"{fname}: {size / 1e6:.1f} MB\")\n",
    "\n",
    "print(\"\\nFiles to download:\")\n",
    "print(\"  food_classifier.pth   — model weights (copy to project root)\")\n",
    "print(\"  food_classes.json     — class names + config (copy to project root)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Export as TorchScript (optional, for faster CPU inference)\n",
    "\n",
    "TorchScript compiles the model for optimized inference without Python overhead.\n",
    "Use this if you deploy on CPU (your Docker containers)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Move to CPU for export (your containers run on CPU)\n",
    "model_cpu = model.cpu()\n",
    "model_cpu.eval()\n",
    "\n",
    "# Trace the model\n",
    "example_input = torch.randn(1, 3, 224, 224)\n",
    "traced_model = torch.jit.trace(model_cpu, example_input)\n",
    "traced_model.save('food_classifier_traced.pt')\n",
    "\n",
    "# Benchmark CPU inference (this is what your containers will do)\n",
    "cpu_times = []\n",
    "for _ in range(50):\n",
    "    start = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        _ = traced_model(example_input)\n",
    "    cpu_times.append((time.perf_counter() - start) * 1000)\n",
    "\n",
    "cpu_times = np.array(cpu_times)\n",
    "print(f\"CPU inference (TorchScript):\")\n",
    "print(f\"  Mean:  {cpu_times.mean():.2f} ms\")\n",
    "print(f\"  P50:   {np.percentile(cpu_times, 50):.2f} ms\")\n",
    "print(f\"  P95:   {np.percentile(cpu_times, 95):.2f} ms\")\n",
    "\n",
    "size = os.path.getsize('food_classifier_traced.pt')\n",
    "print(f\"\\nfood_classifier_traced.pt: {size / 1e6:.1f} MB\")\n",
    "print(\"\\nUse this file for deployment — faster CPU inference.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Download Files\n",
    "\n",
    "Run this cell to download the trained model files to your computer.\n",
    "Then copy them to your `my_product/` project directory."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading model files...\")\n",
    "print(\"Copy these files to: my_product/models/\")\n",
    "print()\n",
    "\n",
    "files.download('food_classifier.pth')\n",
    "files.download('food_classifier_traced.pt')\n",
    "files.download('food_classes.json')\n",
    "files.download('training_history.json')\n",
    "files.download('training_curves.png')\n",
    "files.download('sample_predictions.png')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Quick Test — Classify a Custom Image\n",
    "\n",
    "Upload any food image to test the model before downloading."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from google.colab import files as colab_files\n",
    "from PIL import Image\n",
    "\n",
    "print(\"Upload a food image to test:\")\n",
    "uploaded = colab_files.upload()\n",
    "\n",
    "for filename in uploaded:\n",
    "    # Load and preprocess\n",
    "    img = Image.open(filename).convert('RGB')\n",
    "    img_tensor = test_transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    # Predict\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "\n",
    "    # Top 5 predictions\n",
    "    top5_probs, top5_indices = probs.topk(5)\n",
    "\n",
    "    print(f\"\\nResults for '{filename}':\")\n",
    "    print(\"-\" * 40)\n",
    "    for prob, idx in zip(top5_probs[0], top5_indices[0]):\n",
    "        name = class_names[idx.item()].replace('_', ' ').title()\n",
    "        print(f\"  {name:25s} {100*prob.item():.1f}%\")\n",
    "\n",
    "    # Show image\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    winner = class_names[top5_indices[0][0].item()].replace('_', ' ').title()\n",
    "    plt.title(f\"Prediction: {winner} ({100*top5_probs[0][0].item():.1f}%)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "After downloading the model files:\n",
    "\n",
    "1. Copy `food_classifier.pth` and `food_classes.json` to `my_product/models/`\n",
    "2. The integration code in `ml_food_classifier.py` will load these files\n",
    "3. Run `benchmark_ml.py` to compare A2A vs PNP vs TOON with image payloads\n",
    "\n",
    "Expected model size: ~9 MB (MobileNetV2 is lightweight)"
   ]
  }
 ]
}